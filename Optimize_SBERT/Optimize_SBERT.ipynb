{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac7597b-2177-47f8-884f-b4b4fd6598ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import (\n",
    "    AutoOptimizationConfig,\n",
    "    ORTModelForFeatureExtraction,\n",
    "    ORTOptimizer,\n",
    "    ORTQuantizer\n",
    ")\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig, AutoQuantizationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22b37d2-a75a-4ba2-a34e-14ecdfa7d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and export the model to the ONNX format\n",
    "model_id = \"dangvantuan/sentence-camembert-large\"\n",
    "save_dir = \"camembert_optimized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4941e-08c2-4a28-89e9-a5f838d403e4",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d142ee-2459-40d4-9301-770deb62977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|████████████████████| 400/400 [00:00<00:00, 755kB/s]\n",
      "config.json: 100%|█████████████████████████████| 683/683 [00:00<00:00, 3.56MB/s]\n",
      "sentencepiece.bpe.model: 100%|███████████████| 809k/809k [00:00<00:00, 12.8MB/s]\n",
      "special_tokens_map.json: 100%|██████████████████| 298/298 [00:00<00:00, 617kB/s]\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "model.safetensors: 100%|███████████████████| 1.35G/1.35G [00:21<00:00, 64.1MB/s]\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.1.2\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/Users/satishsilveri/anaconda3/envs/optimum/lib/python3.11/site-packages/optimum/onnxruntime/configuration.py:770: FutureWarning: disable_embed_layer_norm will be deprecated soon, use disable_embed_layer_norm_fusion instead, disable_embed_layer_norm_fusion is set to True.\n",
      "  warnings.warn(\n",
      "Optimizing model...\n",
      "Configuration saved in camembert_optimized/ort_config.json\n",
      "Optimized model saved at: camembert_optimized (external data format: False; saved all tensor to one file: True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('camembert_optimized')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, export=True)\n",
    "\n",
    "# Load the optimization configuration detailing the optimization we wish to apply\n",
    "optimization_config = AutoOptimizationConfig.O3()\n",
    "optimizer = ORTOptimizer.from_pretrained(model)\n",
    "\n",
    "optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a211542-1d4e-482e-a395-a0c6b97dcc63",
   "metadata": {},
   "source": [
    "## Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fb3ecd-2993-4be0-b687-6d7007399d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dynamic quantizer: QOperator (mode: IntegerOps, schema: u8/s8, channel-wise: False)\n",
      "Quantizing model...\n",
      "Saving quantized model at: camembert_optimized_quantized (external data format: False)\n",
      "Configuration saved in camembert_optimized_quantized/ort_config.json\n"
     ]
    }
   ],
   "source": [
    "onnx_model = ORTModelForFeatureExtraction.from_pretrained(save_dir)\n",
    "\n",
    "quantizer = ORTQuantizer.from_pretrained(onnx_model)\n",
    "\n",
    "dqconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=False)\n",
    "\n",
    "model_quantized_path = quantizer.quantize(\n",
    "    save_dir=save_dir+'_quantized',\n",
    "    quantization_config=dqconfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc2fae-e72a-4181-8120-cca22fd1db3c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e1f495-61cf-4f54-ba2f-944d4350fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX file model_optimized_quantized.onnx is not a regular name used in optimum.onnxruntime, the ORTModel might not behave as expected.\n"
     ]
    }
   ],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('camembert_optimized_quantized')\n",
    "\n",
    "model = ORTModelForFeatureExtraction.from_pretrained('camembert_optimized_quantized')\n",
    "\n",
    "embedding = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer, accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f08cbbdb-38d5-4c94-b92e-a7d94f96fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = embedding('Encode this sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c04c96-c016-42d6-86fd-21a0422aaae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744a8d66-98e2-44b6-90c9-ecde7a0650ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6559e2f-bb19-4c23-aacb-1770b7c27981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "535aa855-c5bc-4288-91ec-de191107c665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc7f226c-9928-4f1a-bb8e-e52748fe9333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX file model_optimized_quantized.onnx is not a regular name used in optimum.onnxruntime, the ORTModel might not behave as expected.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('camembert_optimized_quantized')\n",
    "\n",
    "model = ORTModelForFeatureExtraction.from_pretrained('camembert_optimized_quantized')\n",
    "\n",
    "\n",
    "def generate_embeddings(tokenizer, model, sentences):\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8737642-1683-4400-b904-090ed6abec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-0.2923,  0.1488, -0.4010,  ...,  0.1985,  0.3377, -0.0103],\n",
      "        [ 0.0818, -0.0262, -0.2458,  ...,  0.4726, -0.1112,  0.1105]])\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence embeddings:\")\n",
    "sentence_embeddings = generate_embeddings(tokenizer, model, sentences)\n",
    "print(sentence_embeddings)\n",
    "print(len(sentence_embeddings[0]))\n",
    "print(len(sentence_embeddings[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
